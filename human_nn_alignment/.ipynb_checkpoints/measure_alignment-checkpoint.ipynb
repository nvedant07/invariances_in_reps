{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76bb959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NS/twitter_archive2/work/vnanda/minconda3/envs/dl_base/lib/python3.7/site-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import itertools\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import plot_helper as plt_hp\n",
    "import torch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.enabled = False\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fcfc6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /NS/twitter_archive2/work/vnanda/PerceptualSimilarity/lpips/weights/v0.1/alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg16], v[0.1], spatial [off]\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg16], v[0.1], spatial [off]\n",
      "Loading model from: /NS/twitter_archive2/work/vnanda/PerceptualSimilarity/lpips/weights/v0.1/vgg.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg16], v[0.1], spatial [off]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0')\n",
    "kwargs_alex_finetuned={'net': 'alex', \n",
    "        'pretrained': True,\n",
    "        'model_path': '/NS/twitter_archive2/work/vnanda/PerceptualSimilarity/lpips/weights/v0.1/alex.pth'}\n",
    "kwargs_vgg_finetuned={'net': 'vgg16', \n",
    "        'pretrained': True,\n",
    "        'model_path': '/NS/twitter_archive2/work/vnanda/PerceptualSimilarity/lpips/weights/v0.1/vgg.pth'}\n",
    "kwargs_vgg_imagenet={'net': 'vgg16', \n",
    "        'pretrained': False}\n",
    "kwargs_alex_imagenet={'net': 'vgg16', \n",
    "        'pretrained': False}\n",
    "L_objs = [lpips.LPIPS(**kwargs_alex_finetuned).to(device), \n",
    "          lpips.LPIPS(**kwargs_alex_imagenet).to(device), \n",
    "          lpips.LPIPS(**kwargs_vgg_finetuned).to(device), \n",
    "          lpips.LPIPS(**kwargs_vgg_imagenet).to(device)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0d628210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_arch = 'densenet121'\n",
    "# model_arch = 'inceptionv3'\n",
    "# model_arch = 'vgg16'\n",
    "model_arch = 'resnet18'\n",
    "target_image_dataset = 'cifar10'\n",
    "training_dataset = 'cifar10'\n",
    "\n",
    "# model_arch = 'resnet18'\n",
    "# model_arch = 'resnet50'\n",
    "# model_arch = 'vgg16_bn'\n",
    "# target_image_dataset = 'imagenet'\n",
    "# training_dataset = 'imagenet'\n",
    "\n",
    "# append = 'nonrob'\n",
    "# append = 'rob_l2eps3'\n",
    "\n",
    "# append = 'nonrob_rand_seed_2'\n",
    "# append = 'robl2eps1_rand_seed_2'\n",
    "# append = 'rob_l2eps1'\n",
    "# append = 'nonrob_simclraug'\n",
    "# append = 'simclr_all'\n",
    "# append = 'simclr_nocolor'\n",
    "append = 'simclr_adv'\n",
    "\n",
    "\n",
    "seed = 'super-noise'\n",
    "# seed = 'light-noise'\n",
    "\n",
    "reg_free = 'reg_free'\n",
    "human_loss = 'reg_free_transforms_True'\n",
    "# human_loss = 'reg_free_transforms_True_fft'\n",
    "# human_loss = 'freq_transforms_True_fft'\n",
    "# human_loss = 'freq'\n",
    "# adv_loss = 'adv_alex_finetuned'\n",
    "adv_loss = 'adv_alex_imagenet' ## use for cifar10\n",
    "\n",
    "# inversion_losses = ['reg_free', 'freq']\n",
    "# transform_robustness = [True, False]\n",
    "# ffts = [True, False]\n",
    "# additional_losses = ['adv_alex_finetuned', 'adv_alex_finetuned_seed', \n",
    "#                      'adv_alex_imagenet', 'adv_alex_imagenet_seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c27a16d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_alex_imagenet\n",
      "[99.0, 0.0, 84.0, 74.0]\n",
      "Alignment: $0.00_{\\pm 0.00}$\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for loss in [reg_free, human_loss, adv_loss]:\n",
    "for loss in [adv_loss]:\n",
    "    inverted_images_dir = f'./results/generated_images/{training_dataset}/'\\\n",
    "        f'{target_image_dataset}_{model_arch}_{loss}_{append}'\n",
    "    \n",
    "#     seeds = imageio.imread(f'{inverted_images_dir}/{seed}.png')\n",
    "    seeds = np.array(Image.open(f'{inverted_images_dir}/{seed}.png'))\n",
    "    targets, results = None, None\n",
    "    seeds = torch.tensor(np.moveaxis(seeds/255., -1, 0)).to(device)\n",
    "    for result_fpath in glob.glob(f'{inverted_images_dir}/result/*_seed_{seed}.png'):\n",
    "        filename = result_fpath.split('/')[-1]\n",
    "        target_fpath = f'{inverted_images_dir}/target/{filename}'\n",
    "#         target, result = np.moveaxis(imageio.imread(target_fpath)/255., -1, 0), \\\n",
    "#             np.moveaxis(imageio.imread(result_fpath)/255., -1, 0)\n",
    "        target, result = np.moveaxis(np.array(Image.open(target_fpath))/255., -1, 0), \\\n",
    "            np.moveaxis(np.array(Image.open(result_fpath))/255., -1, 0)\n",
    "        target, result = torch.tensor(target).to(device).unsqueeze(0), \\\n",
    "            torch.tensor(result).to(device).unsqueeze(0)\n",
    "        targets = target if targets is None else torch.cat((targets, target))\n",
    "        results = result if results is None else torch.cat((results, result))\n",
    "    seeds = torch.ones((len(targets), *seeds.shape), device=device) * \\\n",
    "        seeds.unsqueeze(0)\n",
    "    \n",
    "    print (loss)\n",
    "    alignments = []\n",
    "    for L in L_objs:\n",
    "        d_res_seed = L(results.float(), seeds.float(), normalize=True).squeeze()\n",
    "        d_res_target = L(results.float(), targets.float(), normalize=True).squeeze()    \n",
    "        alignments.append(100 * torch.sum(d_res_target <= d_res_seed).item()/len(results))\n",
    "    print (alignments)\n",
    "    if loss == adv_loss:\n",
    "        print (f'Alignment: ${np.mean(alignments[1:2]):.2f}_{{\\pm {np.std(alignments[1:2]):.2f}}}$')\n",
    "    else:\n",
    "        print (f'Alignment: ${np.mean(alignments):.2f}_{{\\pm {np.std(alignments):.2f}}}$')\n",
    "    print ()\n",
    "    d_res_target, d_res_seed, targets, results, seeds = None, None, None, None, None\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66bc4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_alignment(target_dataset, source_dataset, architectures, appends):\n",
    "    alignments_mean, alignments_std = [], []\n",
    "    for a in appends:\n",
    "        means, stds = [], []\n",
    "        for arch in architectures:\n",
    "            inverted_images_dir = f'./results/generated_images/{source_dataset}/{target_dataset}_{arch}_{a}'\n",
    "            \n",
    "            if not os.path.exists(f'{inverted_images_dir}/{seed}.png'):\n",
    "                means.append(np.nan)\n",
    "                stds.append(np.nan)\n",
    "                continue\n",
    "\n",
    "            seeds = np.array(Image.open(f'{inverted_images_dir}/{seed}.png'))\n",
    "            targets, results = None, None\n",
    "            seeds = torch.tensor(np.moveaxis(seeds/255., -1, 0)).to(device)\n",
    "            for result_fpath in glob.glob(f'{inverted_images_dir}/result/*_seed_{seed}.png'):\n",
    "                filename = result_fpath.split('/')[-1]\n",
    "                target_fpath = f'{inverted_images_dir}/target/{filename}'\n",
    "                target, result = np.moveaxis(np.array(Image.open(target_fpath))/255., -1, 0), \\\n",
    "                    np.moveaxis(np.array(Image.open(result_fpath))/255., -1, 0)\n",
    "                target, result = torch.tensor(target).to(device).unsqueeze(0), \\\n",
    "                    torch.tensor(result).to(device).unsqueeze(0)\n",
    "                targets = target if targets is None else torch.cat((targets, target))\n",
    "                results = result if results is None else torch.cat((results, result))\n",
    "            seeds = torch.ones((len(targets), *seeds.shape), device=device) * seeds.unsqueeze(0)\n",
    "\n",
    "            alignments = []\n",
    "            for L in L_objs:\n",
    "                d_res_seed = L(results.float(), seeds.float(), normalize=True).squeeze()\n",
    "                d_res_target = L(results.float(), targets.float(), normalize=True).squeeze()    \n",
    "                alignments.append(100 * torch.sum(d_res_target <= d_res_seed).item()/len(results))\n",
    "\n",
    "            means.append(np.mean(alignments))\n",
    "            stds.append(np.std(alignments))\n",
    "\n",
    "        alignments_mean.append(means)\n",
    "        alignments_std.append(stds)\n",
    "    return alignments_mean, alignments_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceab735",
   "metadata": {},
   "source": [
    "## Model Architecture and Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0d8d0e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dataset = 'cifar10'\n",
    "# source_dataset = 'cifar10'\n",
    "# architectures = ['resnet18', 'densenet121', 'vgg16', 'inceptionv3']\n",
    "# appends = ['reg_free_nonrob_rand_seed_2', \n",
    "#            'reg_free_robl2eps1_rand_seed_2',\n",
    "#            'reg_free_tradesbeta0.1eps1',\n",
    "#            'reg_free_tradesbeta1eps1',\n",
    "#            'reg_free_tradesbeta6eps1',\n",
    "#            'reg_free_tradesbeta10eps1',\n",
    "#            'reg_free_martbeta0.1eps1',\n",
    "#            'reg_free_martbeta1eps1',\n",
    "#            'reg_free_martbeta6eps1',\n",
    "#            'reg_free_martbeta10eps1']\n",
    "# legend_vals = ['Standard', 'AT', \n",
    "#                'TRADES (0.1)', 'TRADES (1)', \n",
    "#                'TRADES (6)', 'TRADES (10)', \n",
    "#                'MART (0.1)', 'MART (1)', \n",
    "#                'MART (6)', 'MART (10)']\n",
    "\n",
    "# target_dataset = 'imagenet'\n",
    "# source_dataset = 'imagenet'\n",
    "# architectures = ['resnet18', 'resnet50', 'vgg16_bn']\n",
    "# appends = ['reg_free_nonrob', \n",
    "#            'reg_free_rob_l2eps3']\n",
    "# legend_vals = ['Standard', 'AT']\n",
    "\n",
    "target_dataset = 'cifar100'\n",
    "source_dataset = 'cifar100'\n",
    "architectures = ['resnet18', 'densenet121', 'vgg16', 'inceptionv3']\n",
    "appends = ['reg_free_nonrob', \n",
    "           'reg_free_rob_l2eps1']\n",
    "legend_vals = ['Standard', 'AT']\n",
    "\n",
    "\n",
    "markers = ['s','^',] + ['o'] * (len(appends) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe60aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_mean, alignments_std = \\\n",
    "    measure_alignment(target_dataset, source_dataset, architectures, appends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36339444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'plot_helper' from '../plot_helper.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(plt_hp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06475468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../plot_helper.py:674: UserWarning: marker is redundantly defined by the 'marker' keyword argument and the fmt string \"s\" (-> marker='s'). The keyword argument will take precedence.\n",
      "  fmt=markers[idx] if markers is not None else 'o')\n",
      "../plot_helper.py:674: UserWarning: marker is redundantly defined by the 'marker' keyword argument and the fmt string \"^\" (-> marker='^'). The keyword argument will take precedence.\n",
      "  fmt=markers[idx] if markers is not None else 'o')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'results/cifar100/alignment_due_to_loss_and_archs/cifar100_alignment_robust_vs_nonrobust_scatter.pdf'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 150x150 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_vals = [np.arange(len(architectures))] * len(alignments_mean)\n",
    "plt_hp.scatter_plot(x_vals, alignments_mean, \n",
    "                    labels=None, plot_title='', subfolder='alignment_due_to_loss_and_archs', \n",
    "                    filename=f'{target_dataset}_alignment_robust_vs_nonrobust_scatter', \n",
    "                    x_label='Architecture', y_label='Alignment', extension='pdf', figsize=(8,6), \n",
    "                    x_ticklabels=architectures, x_err=None, y_err=alignments_std, \n",
    "                    legend_vals=legend_vals, paper_friendly_plots=True, \n",
    "                    markers=markers, sizes=[25,25] + [20] * (len(x_vals) - 2), \n",
    "                    results_subfolder_name=source_dataset,\n",
    "                    legend_ncol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6020f91",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8c5ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = 'cifar10'\n",
    "source_dataset = 'cifar10'\n",
    "architectures = ['resnet18', 'densenet121', 'vgg16', 'inceptionv3']\n",
    "\n",
    "nonrob_appends = ['reg_free_nonrob_rand_seed_2', 'reg_free_nonrob_simclraug']\n",
    "rob_appends = ['reg_free_robl2eps1_rand_seed_2', 'reg_free_rob_noaug']\n",
    "\n",
    "\n",
    "alignments_mean_nonrob, alignments_std_nonrob = measure_alignment(target_dataset, source_dataset, \n",
    "                                                    architectures, nonrob_appends)\n",
    "alignments_mean_rob, alignments_std_rob = measure_alignment(target_dataset, source_dataset, \n",
    "                                                    architectures, rob_appends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98d6790d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_free_nonrob_rand_seed_2, resnet18, $0.00_{\\pm 0.00}$\n",
      "reg_free_nonrob_rand_seed_2, densenet121, $0.00_{\\pm 0.00}$\n",
      "reg_free_nonrob_rand_seed_2, vgg16, $0.00_{\\pm 0.00}$\n",
      "reg_free_nonrob_rand_seed_2, inceptionv3, $0.00_{\\pm 0.00}$\n",
      "reg_free_nonrob_simclraug, resnet18, $0.00_{\\pm 0.00}$\n",
      "reg_free_nonrob_simclraug, densenet121, $1.00_{\\pm 1.73}$\n",
      "reg_free_nonrob_simclraug, vgg16, $0.00_{\\pm 0.00}$\n",
      "reg_free_nonrob_simclraug, inceptionv3, $0.00_{\\pm 0.00}$\n",
      "\n",
      "\n",
      "reg_free_robl2eps1_rand_seed_2, resnet18, $76.50_{\\pm 15.91}$\n",
      "reg_free_robl2eps1_rand_seed_2, densenet121, $93.50_{\\pm 9.60}$\n",
      "reg_free_robl2eps1_rand_seed_2, vgg16, $0.25_{\\pm 0.43}$\n",
      "reg_free_robl2eps1_rand_seed_2, inceptionv3, $24.25_{\\pm 25.17}$\n",
      "reg_free_rob_noaug, resnet18, $30.00_{\\pm 12.02}$\n",
      "reg_free_rob_noaug, densenet121, $93.75_{\\pm 8.20}$\n",
      "reg_free_rob_noaug, vgg16, $1.00_{\\pm 1.73}$\n",
      "reg_free_rob_noaug, inceptionv3, $12.25_{\\pm 20.08}$\n"
     ]
    }
   ],
   "source": [
    "for a, means, stds in zip(nonrob_appends, alignments_mean_nonrob, alignments_std_nonrob):\n",
    "    for arch, m, s in zip(architectures, means, stds):\n",
    "        print (f'{a}, {arch}, ${m:.2f}_{{\\pm {s:.2f}}}$')\n",
    "print ()\n",
    "print ()\n",
    "for a, means, stds in zip(rob_appends, alignments_mean_rob, alignments_std_rob):\n",
    "    for arch, m, s in zip(architectures, means, stds):\n",
    "        print (f'{a}, {arch}, ${m:.2f}_{{\\pm {s:.2f}}}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b05e1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_dataset = 'imagenet'\n",
    "# source_dataset = 'imagenet'\n",
    "# architectures = ['resnet18', 'resnet50']\n",
    "\n",
    "# rob_appends = ['reg_free_freerob_linf', 'reg_free_freerob_linf_noaug']\n",
    "\n",
    "\n",
    "target_dataset = 'cifar100'\n",
    "source_dataset = 'cifar100'\n",
    "architectures = ['resnet18', 'vgg16', 'densenet121', 'inceptionv3']\n",
    "\n",
    "rob_appends = ['reg_free_rob_l2eps1', 'reg_free_rob_l2eps1_noaug']\n",
    "\n",
    "\n",
    "alignments_mean_rob, alignments_std_rob = measure_alignment(target_dataset, source_dataset, \n",
    "                                                    architectures, rob_appends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "411383b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_free_rob_l2eps1, resnet18, $82.50_{\\pm 20.85}$\n",
      "reg_free_rob_l2eps1, vgg16, $58.75_{\\pm 32.15}$\n",
      "reg_free_rob_l2eps1, densenet121, $88.00_{\\pm 14.51}$\n",
      "reg_free_rob_l2eps1, inceptionv3, $69.25_{\\pm 26.39}$\n",
      "reg_free_rob_l2eps1_noaug, resnet18, $81.50_{\\pm 15.58}$\n",
      "reg_free_rob_l2eps1_noaug, vgg16, $46.25_{\\pm 32.25}$\n",
      "reg_free_rob_l2eps1_noaug, densenet121, $89.75_{\\pm 15.01}$\n",
      "reg_free_rob_l2eps1_noaug, inceptionv3, $84.75_{\\pm 13.70}$\n"
     ]
    }
   ],
   "source": [
    "for a, means, stds in zip(rob_appends, alignments_mean_rob, alignments_std_rob):\n",
    "    for arch, m, s in zip(architectures, means, stds):\n",
    "        print (f'{a}, {arch}, ${m:.2f}_{{\\pm {s:.2f}}}$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069d0e14",
   "metadata": {},
   "source": [
    "## SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fb594d00",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/generated_images/cifar100/cifar100_resnet18_reg_free_simclr_nocolor_249/super-noise.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1914281/1594548163.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                     architectures, appends_all)\n\u001b[1;32m     18\u001b[0m alignments_mean_nocolor, alignments_std_nocolor = measure_alignment(target_dataset, source_dataset, \n\u001b[0;32m---> 19\u001b[0;31m                                                     architectures, appends_nocolor)\n\u001b[0m\u001b[1;32m     20\u001b[0m alignments_mean_adv, alignments_std_adv = measure_alignment(target_dataset, source_dataset, \n\u001b[1;32m     21\u001b[0m                                                     architectures, appends_adv)\n",
      "\u001b[0;32m/tmp/ipykernel_1914281/856652840.py\u001b[0m in \u001b[0;36mmeasure_alignment\u001b[0;34m(target_dataset, source_dataset, architectures, appends)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0minverted_images_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'./results/generated_images/{source_dataset}/{target_dataset}_{arch}_{a}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{inverted_images_dir}/{seed}.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mseeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseeds\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/NS/twitter_archive2/work/vnanda/minconda3/envs/dl_base/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2952\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2953\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2954\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/generated_images/cifar100/cifar100_resnet18_reg_free_simclr_nocolor_249/super-noise.png'"
     ]
    }
   ],
   "source": [
    "# target_dataset = 'cifar10'\n",
    "# source_dataset = 'cifar10'\n",
    "target_dataset = 'cifar100'\n",
    "source_dataset = 'cifar100'\n",
    "architectures = ['resnet18']\n",
    "\n",
    "epochs = range(49, 1000, 50)\n",
    "\n",
    "appends_all = [f'reg_free_simclr_all_{e}' for e in epochs]\n",
    "appends_nocolor = [f'reg_free_simclr_nocolor_{e}' for e in epochs]\n",
    "appends_adv = [f'reg_free_simclr_adv_{e}' for e in epochs]\n",
    "\n",
    "# appends_sup_rob = ['reg_free_robl2eps1_rand_seed_2']\n",
    "appends_sup_rob = ['reg_free_rob_l2eps1']\n",
    "\n",
    "alignments_mean_all, alignments_std_all = measure_alignment(target_dataset, source_dataset, \n",
    "                                                    architectures, appends_all)\n",
    "alignments_mean_nocolor, alignments_std_nocolor = measure_alignment(target_dataset, source_dataset, \n",
    "                                                    architectures, appends_nocolor)\n",
    "alignments_mean_adv, alignments_std_adv = measure_alignment(target_dataset, source_dataset, \n",
    "                                                    architectures, appends_adv)\n",
    "alignments_mean_sup, alignments_std_sup = measure_alignment(target_dataset, source_dataset, \n",
    "                                                    architectures, appends_sup_rob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66271433",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_mean_adv, alignments_std_adv = \\\n",
    "    np.array(alignments_mean_adv).squeeze(), np.array(alignments_std_adv).squeeze()\n",
    "alignments_mean_nocolor, alignments_std_nocolor = \\\n",
    "    np.array(alignments_mean_nocolor).squeeze(), np.array(alignments_std_nocolor).squeeze()\n",
    "alignments_mean_all, alignments_std_all = \\\n",
    "    np.array(alignments_mean_all).squeeze(), np.array(alignments_std_all).squeeze()\n",
    "alignments_mean_sup, alignments_std_sup = np.array(alignments_mean_sup).squeeze(), \\\n",
    "    np.array(alignments_std_sup).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc536d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_mean_sup, alignments_std_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_hp.line_plot([alignments_mean_all, alignments_mean_adv, alignments_mean_nocolor], \n",
    "                 'Epoch', 'Alignment', '', 'alignment_due_to_training_paradigm', \n",
    "                 f'{target_dataset}_{architectures[0]}_simclr', extension='png', \n",
    "                 x_vals=list(epochs), vertical_line=None, \n",
    "                 legend_vals=['SimCLR DA', 'SimCLR (DA + Adv)', \n",
    "                              'SimCLR (DA - color)', 'Supervised AT\\n(best model)'], \n",
    "                 horizontal_lines=[float(alignments_mean_sup)], \n",
    "                 horizontal_lines_err=[float(alignments_std_sup)], \n",
    "                 colors=None, linestyles=['-', '-', '-', '--'],legend_ncol=2,\n",
    "                 y_lims=None, root_dir='.', paper_friendly_plots=True, plot_inside=False, \n",
    "                 legend_location='best', savefig=True, figsize=(10,4), \n",
    "                 marker=['o', 'o', 'o', 'o'], results_subfolder_name=source_dataset, \n",
    "                 grid_spacing=None, y_err=[alignments_std_all, alignments_std_adv, alignments_std_nocolor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c753f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
