{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db328b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "import itertools\n",
    "from functools import partial\n",
    "\n",
    "import sys\n",
    "paths_to_add = ['..', \n",
    "                '../deep-learning-base', \n",
    "                '../deep-learning-base/training', \n",
    "                '../deep-learning-base/datasets',\n",
    "                '../deep-learning-base/architectures', \n",
    "                '../deep-learning-base/attack',\n",
    "                '../deep-learning-base/self_supervised']\n",
    "for p in paths_to_add:\n",
    "    if p not in sys.path:\n",
    "        sys.path.append(p)\n",
    "\n",
    "from training import LitProgressBar, NicerModelCheckpointing\n",
    "import training.finetuning as ft\n",
    "import architectures as arch\n",
    "from architectures.callbacks import LightningWrapper, MultimodalEvalWrapper\n",
    "from training.trainer_callback import ZeroShotCallback\n",
    "from data_modules import DATA_MODULES\n",
    "import dataset_metadata as dsmd\n",
    "from partially_inverted_reps import DATA_PATH_IMAGENET, DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02744f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATASET = 'clip' # used for mean and std and test-time transforms\n",
    "EVAL_DATASETS = ['cifar10', 'cifar100', 'oxford-iiit-pets', 'flowers', 'stl10']\n",
    "CLASS_PROMPTS = ['a photo of a ', 'this is a photo of a ', 'this is a photo of ', \n",
    "                 'the following is a photo of ', 'this is a ']\n",
    "MODELS = ['resnet50', 'resnet101', 'vit_base_patch32_224', 'vit_base_patch16_224']\n",
    "BATCH_SIZE = 512\n",
    "DEVICES = [1]\n",
    "ACCELERATOR = \"gpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f9c066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n",
      "../deep-learning-base/architectures/__init__.py:143: UserWarning: No CLIP checkpoint given, using default CLIP model: /NS/robustness_2/work/vnanda/invariances_in_reps/deep-learning-base/checkpoints/clip/RN50.pt\n",
      "  warnings.warn(f'No CLIP checkpoint given, using default CLIP model: {CLIP_MODEL_PATHS[model_name]}')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3933242/1126219901.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                            callback=partial(MultimodalEvalWrapper,\n\u001b[1;32m      6\u001b[0m                                             dataset_name=BASE_DATASET),\n\u001b[0;32m----> 7\u001b[0;31m                            multimodal_clip=True)\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0meval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_prompt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEVAL_DATASETS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLASS_PROMPTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         dm = DATA_MODULES[eval_dataset](\n",
      "\u001b[0;32m/NS/robustness_2/work/vnanda/invariances_in_reps/deep-learning-base/architectures/__init__.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_name, dataset_name, pretrained, checkpoint_path, seed, loading_function, callback, num_classes, loading_function_kwargs, use_timm_for_cifar, multimodal_clip)\u001b[0m\n\u001b[1;32m    166\u001b[0m                                                    checkpoint_path, **loading_function_kwargs)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/NS/robustness_2/work/vnanda/invariances_in_reps/deep-learning-base/architectures/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, scale, class_prompt, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mclass_prompt\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0madded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \"\"\"\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/NS/robustness_2/work/vnanda/invariances_in_reps/deep-learning-base/architectures/callbacks.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, mean, std, loss, lr, weight_decay, momentum, step_lr, step_lr_gamma, dataset_name, inference_kwargs, optimizer, warmup_steps, total_steps, training_params_dataset)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0mtraining_params_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_PARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_params_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET_PARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_params_dataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'loss'"
     ]
    }
   ],
   "source": [
    "for model in MODELS:\n",
    "    m1 = arch.create_model(model, BASE_DATASET, \n",
    "                           pretrained=True, checkpoint_path='', \n",
    "                           num_classes=dsmd.DATASET_PARAMS[BASE_DATASET]['num_classes'],\n",
    "                           callback=partial(MultimodalEvalWrapper,\n",
    "                                            dataset_name=BASE_DATASET),\n",
    "                           multimodal_clip=True)\n",
    "    for eval_dataset, class_prompt in itertools.product(EVAL_DATASETS, CLASS_PROMPTS):\n",
    "        dm = DATA_MODULES[eval_dataset](\n",
    "            data_dir=DATA_PATH_IMAGENET if 'imagenet' in eval_dataset else DATA_PATH,\n",
    "            transform_train=dsmd.DATASET_PARAMS[BASE_DATASET]['transform_test'],\n",
    "            transform_test=dsmd.DATASET_PARAMS[BASE_DATASET]['transform_test'],\n",
    "            batch_size=BATCH_SIZE)\n",
    "        dm.init_remaining_attrs(BASE_DATASET)\n",
    "        \n",
    "        m1._set_classes(dm.train_ds.classes)\n",
    "        m1._set_class_prompt(class_prompt)\n",
    "        \n",
    "        t = Trainer(accelerator='gpu', devices=1, \n",
    "                    deterministic=True, num_sanity_val_steps=0)\n",
    "        out = t.predict(self, \n",
    "                dataloaders=[dm.val_dataloader(),\n",
    "                             dm.test_dataloader()])\n",
    "        print (len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b9f522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
