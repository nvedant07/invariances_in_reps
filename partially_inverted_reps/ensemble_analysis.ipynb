{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0352b825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/NS/twitter_archive2/work/vnanda/minconda3/envs/dl_base/lib/python3.7/site-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5,6'\n",
    "\n",
    "from pytorch_lightning import utilities as pl_utils\n",
    "from pytorch_lightning.trainer.trainer import Trainer\n",
    "from pytorch_lightning.plugins import DDPPlugin, DataParallelPlugin\n",
    "import torch, glob\n",
    "import torch.nn as nn\n",
    "import itertools\n",
    "import pathlib, argparse\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "sys.path.append('../deep-learning-base')\n",
    "\n",
    "import plot_helper as plt_hp\n",
    "import output as out\n",
    "from training import LitProgressBar, NicerModelCheckpointing\n",
    "import training.finetuning as ft\n",
    "import architectures as arch\n",
    "from architectures.callbacks import AdvAttackWrapper\n",
    "from attack.callbacks import AdvCallback\n",
    "from datasets.data_modules import DATA_MODULES\n",
    "import datasets.dataset_metadata as dsmd\n",
    "from partially_inverted_reps.partial_loss import PartialInversionLoss, PartialInversionRegularizedLoss\n",
    "from partially_inverted_reps import DATA_PATH_IMAGENET, DATA_PATH, SERVER_PROJECT_PATH\n",
    "from training.partial_inference_layer import EnsembleHead, HardEnsembleLoss\n",
    "\n",
    "\n",
    "BASE_DATASET = 'imagenet'\n",
    "FINETUNING_DATASETS = ['cifar10', 'cifar100', 'flowers', 'oxford-iiit-pets']\n",
    "MODEL = 'resnet50'\n",
    "BATCH_SIZE = 100\n",
    "CHECKPOINT_PATHS = {\n",
    "    'nonrob': '',\n",
    "    'robustl2eps3': \\\n",
    "    '/NS/robustness_2/work/vnanda/adv-robustness/logs/robust_imagenet/eps3/resnet-50-l2-eps3.ckpt'\n",
    "}\n",
    "APPEND_PATH = 'nonrob'\n",
    "MODE = 'random'\n",
    "MODEL_LOSSES = {\n",
    "    'hard': HardEnsembleLoss(nn.CrossEntropyLoss(reduction='none')),\n",
    "    'soft': None\n",
    "}\n",
    "\n",
    "\n",
    "SEED = 2\n",
    "NUM_NODES = 1\n",
    "DEVICES = 2\n",
    "STRATEGY = DataParallelPlugin() if DEVICES > 1 else None\n",
    "\n",
    "PARTIAL_CHOICE_SEEDS = range(1,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c051f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ensemble_preds(append_path, ensemble_type):\n",
    "    dataset_to_clean_accs, dataset_to_rob_accs = {}, {}\n",
    "    for FINETUNING_DATASET in FINETUNING_DATASETS:\n",
    "        dm = DATA_MODULES[FINETUNING_DATASET](\n",
    "            data_dir=DATA_PATH_IMAGENET if 'imagenet' in FINETUNING_DATASET else DATA_PATH,\n",
    "            transform_train=dsmd.TRAIN_TRANSFORMS_TRANSFER_DEFAULT(224),\n",
    "            transform_test=dsmd.TEST_TRANSFORMS_DEFAULT(224),\n",
    "            batch_size=BATCH_SIZE)\n",
    "        dm.init_remaining_attrs(BASE_DATASET)\n",
    "\n",
    "        m1 = arch.create_model(MODEL, BASE_DATASET, pretrained=True,\n",
    "                               checkpoint_path=CHECKPOINT_PATHS[append_path], \n",
    "                               seed=SEED, \n",
    "                               callback=partial(AdvAttackWrapper,\n",
    "                                                dataset_name=BASE_DATASET,\n",
    "                                                return_adv_samples=True,\n",
    "                                                loss=MODEL_LOSSES[ensemble_type]\n",
    "                                                )) ## assign mean and std from source dataset\n",
    "        PARTIAL_FRACTIONS = sorted(\n",
    "            list(set(\n",
    "                [float(x.split('/frac-')[1].split('-')[0]) for x in \\\n",
    "                    glob.glob(f'./checkpoints/{MODEL}-base-'\n",
    "                              f'{BASE_DATASET}-ft-{FINETUNING_DATASET}/'\n",
    "                              f'*-bs-256')]\n",
    "            )))\n",
    "        frac_to_layers = OrderedDict()\n",
    "        for frac, seed in itertools.product(PARTIAL_FRACTIONS, PARTIAL_CHOICE_SEEDS):\n",
    "            FINETUNED_CHECKPOINT = glob.glob(\n",
    "                f'./checkpoints/{MODEL}-base-'\n",
    "                f'{BASE_DATASET}-ft-{FINETUNING_DATASET}/'\n",
    "                f'frac-{frac:.5f}-mode-{MODE}-seed-{seed}-lr-0.1-bs-256/'\n",
    "                f'{APPEND_PATH}/*-topk=1.ckpt')\n",
    "            if len(FINETUNED_CHECKPOINT) == 0:\n",
    "                continue\n",
    "            FINETUNED_CHECKPOINT = FINETUNED_CHECKPOINT[0]\n",
    "            state_dict = torch.load(FINETUNED_CHECKPOINT)\n",
    "            new_layer = ft.setup_model_for_finetuning(\n",
    "                m1.model, \n",
    "                dsmd.DATASET_PARAMS[FINETUNING_DATASET]['num_classes'],\n",
    "                MODE, frac, seed, inplace=False)\n",
    "            new_layer.load_state_dict({'.'.join(k.split('.')[-2:]):v \\\n",
    "                                        for k,v in state_dict['state_dict'].items()}, strict=True)\n",
    "            if hasattr(new_layer, 'neuron_indices') and 'neuron_indices' in state_dict:\n",
    "                assert torch.all(new_layer.neuron_indices == state_dict['neuron_indices'])\n",
    "            frac_to_layers[frac] = frac_to_layers[frac] + [new_layer] \\\n",
    "                if frac in frac_to_layers else [new_layer]\n",
    "        \n",
    "        pl_utils.seed.seed_everything(SEED, workers=True)\n",
    "        adv_callback = AdvCallback(constraint_train='2',\n",
    "                               eps_train=3.,\n",
    "                               step_size=1.,\n",
    "                               iterations_train=10,\n",
    "                               iterations_test=100,\n",
    "                               random_start_train=False,\n",
    "                               random_restarts_train=0,\n",
    "                               return_image=True, \n",
    "                               do_tqdm=False,\n",
    "                               custom_loss=MODEL_LOSSES[ensemble_type])\n",
    "        trainer = Trainer(accelerator='gpu',\n",
    "                          devices=DEVICES,\n",
    "                          num_nodes=NUM_NODES,\n",
    "                          strategy=STRATEGY,\n",
    "                          log_every_n_steps=1,\n",
    "                          auto_select_gpus=True,\n",
    "                          deterministic=True,\n",
    "                          check_val_every_n_epoch=1,\n",
    "                          num_sanity_val_steps=0,\n",
    "                          sync_batchnorm=True,\n",
    "                          callbacks=[\n",
    "                            LitProgressBar(['loss',\n",
    "                                            'running_acc_clean',\n",
    "                                            'running_acc_adv']),\n",
    "                            adv_callback])\n",
    "\n",
    "        frac_to_clean_acc, frac_to_rob_acc = [], []\n",
    "        name, _ = list(m1.model.named_modules())[-1]\n",
    "        for frac in PARTIAL_FRACTIONS:\n",
    "            print (FINETUNING_DATASET, frac)\n",
    "            m1.model.__setattr__(name, EnsembleHead(frac_to_layers.get(frac), ensemble_type))\n",
    "            predictions = trainer.predict(m1, dataloaders=[dm.test_dataloader()])\n",
    "            if trainer.is_global_zero:\n",
    "                clean_pred = torch.argmax(predictions[0][1], 1)\n",
    "                adv_pred = torch.argmax(predictions[1][1], 1)\n",
    "                y = predictions[2]\n",
    "                frac_to_clean_acc.append(torch.sum(clean_pred == y)/len(y))\n",
    "                frac_to_rob_acc.append(torch.sum(adv_pred == y)/len(y))\n",
    "        \n",
    "        dataset_to_clean_accs[FINETUNING_DATASET] = frac_to_clean_acc\n",
    "        dataset_to_rob_accs[FINETUNING_DATASET] = frac_to_rob_acc\n",
    "    return dataset_to_clean_accs, dataset_to_rob_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b5228f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(dataset_to_clean_accs, dataset_to_rob_accs, append_path, ensemble_type):\n",
    "    for FINETUNING_DATASET in FINETUNING_DATASETS:\n",
    "        plt_str = '<<TableOfContents()>>\\n\\n'\\\n",
    "            f'== Ensemble Predictions ==\\n\\n=== {FINETUNING_DATASET} ===\\n\\n'\n",
    "        frac_to_clean_acc, frac_to_rob_acc = \\\n",
    "            dataset_to_clean_accs[FINETUNING_DATASET], dataset_to_rob_accs[FINETUNING_DATASET]\n",
    "        baseline_clean, baseline_rob = frac_to_clean_acc[-1], frac_to_rob_acc[-1]\n",
    "        x_vals = [PARTIAL_FRACTIONS[idx] for idx in range(len(frac_to_clean_acc[:-1]))]\n",
    "        plt_str += '{}\\n\\n'.format(plt_hp.get_wiki_link(plt_hp.line_plot(\n",
    "            [frac_to_clean_acc[:-1], frac_to_rob_acc[:-1]], \n",
    "            'Fraction of neurons', 'Ensemble Accuracy', FINETUNING_DATASET, \n",
    "            subfolder=BASE_DATASET, \n",
    "            filename=f'{MODEL}_{FINETUNING_DATASET}_{append_path}_{ensemble_type}', \n",
    "            extension='png', x_vals=x_vals, \n",
    "            legend_vals=['Clean Acc', 'Robust Acc ' + r'($\\ell_2 \\epsilon = 3$)', \n",
    "                'Clean (Full Layer)', 'Rob (Full Layer)'], \n",
    "            vertical_line=None, horizontal_lines=[baseline_clean, baseline_rob], \n",
    "            colors=[plt_hp.COLORS[0], plt_hp.COLORS[1], plt_hp.COLORS[0], plt_hp.COLORS[1]], \n",
    "            linestyles=['-', '-', ':', ':'], y_lims=(0.,1.), root_dir='./partially_inverted_reps', \n",
    "            paper_friendly_plots=False, plot_inside=False, legend_location='best', \n",
    "            savefig=True, figsize=(10,6), marker=[True, True, False, False], \n",
    "            results_subfolder_name='ensemble_analysis', grid_spacing=None, \n",
    "            legend_ncol=None), SERVER_PROJECT_PATH, size=700))\n",
    "        with open(f'partially_inverted_reps/results/ensemble_analysis/{BASE_DATASET}/'\n",
    "                  f'wiki_results_{FINETUNING_DATASET}-{append_path}-{ensemble_type}.txt', 'w') as fp:\n",
    "            fp.write(plt_str)\n",
    "        out.upload_results(['partially_inverted_reps/{}/{}/{}'.format(\n",
    "            plt_hp.RESULTS_FOLDER_NAME, \n",
    "            'ensemble_analysis', BASE_DATASET)], \n",
    "            f'partially_inverted_reps/{plt_hp.RESULTS_FOLDER_NAME}', \n",
    "            SERVER_PROJECT_PATH, '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635631c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2\n",
      "Global seed set to 2\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5,6]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fd075d29bef4fae84d4b26bf46b5c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "append_path = 'robustl2eps3'\n",
    "ensemble_type = 'hard'\n",
    "clean_accs_rob_hard, rob_accs_rob_hard = generate_ensemble_preds(append_path, ensemble_type)\n",
    "plotter(clean_accs_rob, rob_accs_rob, append_path, ensemble_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da087e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "append_path = 'robustl2eps3'\n",
    "ensemble_type = 'soft'\n",
    "clean_accs_rob_soft, rob_accs_rob_soft = generate_ensemble_preds(append_path, ensemble_type)\n",
    "plotter(clean_accs_rob, rob_accs_rob, append_path, ensemble_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3fdbd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
